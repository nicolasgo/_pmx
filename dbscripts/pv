#!/usr/bin/python

'''
 PV parses nginx access logs to compute user sessions

 Copyright (c) 2014, 2015, Pragmex Inc, All Right Reserved
 http://pragmex.com/
 
'''

# TODO: compute POSTs (search, uploads etc)

import sys 
import operator
import datetime
from collections import Counter
import fileinput
from optparse import OptionParser
import binascii
import socket

import traceback

import re

#
# some variables
# Global variables

#coverage = 100 # a number from 1 to 100 giving the % of users to profile
#session_length=20*60 # session length in seconds

line_nginx_full = re.compile(r"""\[(?P<dateandtime>\d{2}\/[a-z]{3}\/\d{4}:\d{2}:\d{2}:\d{2} (\+|\-)\d{4})\] ((\"(GET|POST|HEAD) )(?P<url>.+)(http\/1\.1")) (?P<statuscode>\d{3}) (?P<bytessent>\d+) (["](?P<referer>(\-)|(.*))["]) (["](?P<useragent>.*)["]) (?P<id>\w+)""", re.IGNORECASE)

pageviews = Counter()

ONEUSER=False # will be True if -u option is ON
coverage = 100 # a number from 1 to 100.
session_length=30*60 # session length in seconds

hoursum=[0]*24

undefined = {} # to store all undefined strings 
users = Counter()
userdata = {}
userlist = Counter()
intervals = {} # for the time filters intervals (-time option)
output = sys.stdout

notneeded = ['apple-touch-icon-57x57.png','static','favicon.ico','ga','facebook','twitter','proxy','apple-touch-icon-72x72.png','apple-touch-icon-114x114.png','apple-touch-icon-144x144.png']


##
## Here we go!
##

total =0 # counts the total number of pages with / or 302
 
parser = OptionParser()
parser.add_option('-d', '--debug',action="store_true", default=False,
    help='Activates tracing.')
parser.add_option('-o', '--output',
    help='Specifies the output file.  The default is stdout.')
parser.add_option('-f', '--filter',
    help='Specifies the file containing the msisdn to filter. The default is no filter list.')
parser.add_option('-u', '--user',
    help='Filters that filters anything but this user. The default is no user filter.')
parser.add_option('-t', '--time',
    help='Filters based on time. Time is specified in comma separated hours (12,13,14), or hour intervals (12-14) The default is no time filter.')
parser.add_option('-s', '--summary',
    help='List a summary of the top. The default is YES.')
parser.add_option('-l', '--session_length',
    help='The session length in minutes. Default is 20 minutes')
parser.add_option('-p', '--coverage',
    help='A number from 1 to 100 to define the % of users to scan. The default coverage is 100.')


options, files = parser.parse_args()

if options.output and options.output != '-':
   output=sys.stdout = open(options.output, 'w')

if options.coverage and options.coverage != '-':
  coverage=int(options.coverage)
  if coverage < 1:
    coverage=1
  elif coverage > 100:
    coverage=100

# Options to 
if options.time and options.time != '-':
  for s in options.time.split(','):
    t=s.split('-')
    trace( t )
    if len(t)==2:
      for x in range(int(t[0]),int(t[1])+1):
        intervals[x]=1
    else:
      intervals[int(t[0])]=1

if options.session_length and options.session_length != '-':
  session_length= int(options.session_length)*60 # store the session length in seconds

# The user option has priority over the filter option
if options.user and options.user != '-':
  userlist[options.user] += 1
  ONEUSER=True
else:
  if options.filter and options.filter != '-':
    for line in fileinput.input(options.filter):
      fltrd=line.split(':')[0].strip()
      trace('filtering'.join(fltrd))
      userlist[fltrd] +=1

def trace(line):
  if options.debug:
    sys.stderr.write(line+'\n')
#
# print options:
#
if options.debug:
   trace('DEBUG mode')

trace('coverage: '+str(coverage))
trace('time intervals: '+str(intervals))
if ONEUSER:
  trace('ONEUSER: %s msisdn= %s, %s'%(str(ONEUSER),userlist.keys()[0], type(userlist.keys()[0])))
else:
  trace('ONEUSER: '.join(str(ONEUSER)))

if ONEUSER==False and len(userlist.keys())>0:
  trace('Filter list is filtering'+len(userlist.keys())+'users')



def parse_log(line):
    line=line.strip()

    retcode=0 # invalid, it means that we could not parse this string
    useragent = 'unknown'
    numbytes=0
    ip='0.0.0.0'
    msisdn=path=''
    time=datetime.datetime(1970,1,1)
    array=[]

    if not (line.startswith('#') or len(line)==0):
        first = line.split(' - ')

        ip = first[0].split(' ')[0]

        try:
            match = line_nginx_full.search(first[1])

            if not match:
                #trace("^^^^^^^^^ No match with:")
                #trace(line)
                pass
            else:
                dct = match.groupdict()
                time = dct['dateandtime']
                path = dct['url']
                numbytes = int(dct['bytessent'])
                msisdn = dct['id']
                retcode = int(dct['statuscode'])
                useragent = dct['useragent']
                
                time = datetime.datetime.strptime(time.rpartition(' ')[0],  "%d/%b/%Y:%H:%M:%S" )
        except:
            trace(line)
            pass #raise


    return time, msisdn, useragent, path, retcode, numbytes, binascii.hexlify(socket.inet_aton(ip))

#
# inc_pageviews increments the number of pageviews for each root and store that in the pageviews Counter
# inputs:
#    - path: the url path (e.g., /profile/22084494/inbox)
def inc_pageviews(path):
    path= path.split('/')
    root=path[1] # all paths start with a '/', so item #1 is what is after the first slash
    
    if root in notneeded: # we do not need to count this request as a pageview
        root=None

    # TODO: we will need to add a elif to check if this is a media request. In that case, we do not count this as a pageview either.
    # or should we move this elsewhere??
    
    else:
        if root.startswith('?'):
            root='__qparam__'
        elif root.startswith('profile'): 
            # profile is too vague so we need to add the 3rd component. 
            # The 2nd component is for the user_id like in /profile/17548/inbox, /profile/17548/activities, /profile/17548/media
            try:
                part='/'+path[3].split('?')[0]
                root=part[1:]
            except:
                pass

        root = root.split('?')[0]

        pageviews[root] += 1

    return root

# 
# keep() applies the desired filter and returns True if we should monitor that record
#
def keep(time,msisdn,useragent,path,retcode):
    keep_it=True
    if retcode == 0 or retcode <> 200:
        keep_it=False
#        print 'F1'

    # filter out any hour that was not mentioned in the intervals given by the -time option
    if keep_it and len(intervals) > 0:
        keep_it=(time.hour in intervals)
#        print 'F2'
    
#    if keep_it:
#        keep_it=(int(str(msisdn/47)[-2:]) < coverage) # is True when the last 2 msisdn digits are lower than desired coverage
 
    if keep_it:
        # Additional filter to keep only msisdn in the --filter list (option)
        keep_it= len(userlist)==0 or (len(userlist)>0 and userlist[msisdn] != 0)
	#trace('msisdn: %s, keep=%i'%(msisdn,keep_it))
        
    return keep_it

pages_to_count=['inbox', 'mymedia', 'conversaciones', 'activities', 'home', 'friends', 'info', 'media', 'upload', 'avatar', 'publish', 'help']
def print_pagecounts(output, pages):
    for k in pages_to_count:
        print >>output, '%d,'%(pages[k]),
    
def print_header(output):
    print >>output, 'msisdn, time, duration, bytes, ip, pv, variety, landpage, device,',
    for i in range(0,len(pages_to_count)):
        print >>output, '%s,'%(pages_to_count[i][:5]),
    print >>output, 'ua'
        

def print_oneuser(output, msisdn, count):
    d=userdata[msisdn]
    d['session']= sorted(d['session'],key=lambda s: s['time']) # sort sessions by time otherwise this is messy

    for s in d['session']:
        device='0'
        idx=s['ua'].find('ndroid')
        if idx>0:
            device=s['ua'][idx-1:idx+11].strip(',')
            
        print >>output, '%s, %s, %s, %d, %8s,'%(msisdn,s['time'], s['duration'], s['bytes'], s['ip'] ),
        print >>output, '%3d,%d,%-6s,%s,' % (s['pv'], len(s['pages']), '/'+s['path'][:5],device),
        print_pagecounts(output, s['pages'])
        print >>output, '\"'+s['ua']+'\"'


# 
# targetcount: only prints users with at least targetcount pageviews
# limit: limits the number of users to print
#
# output is csv-like
# 
def print_users(output,targetcount=0,limit=None):
    print_header(output) # csv header

    for msisdn, count in users.most_common(limit):
        if msisdn > 10: # msisdn <1000 are for internal use.
            if count < targetcount:
                break
            print_oneuser(output,msisdn,count)



#
# add_user() to the users Counter and computes the session
# msisdn: msisdn of the user
# time: time of the event
# pathroot: root of the url path (e.g., /home, /profile etc). Set to None will only compute the numbytes and not the pageview.
#
def add_user(msisdn, time, pathroot, useragent, ip, numbytes):
    if msisdn > 10: # msisdn below 1000 are for error codes. all msisdn are fairly large numbers: 525145946440
        users[msisdn] += 1

    if msisdn not in userdata: # create the first session entry (min session is 10 secs)
        session={'time':time,'pv':1,'duration':10,'path':pathroot, 'ip':ip, 'ua':useragent, 'pages':Counter(), 'bytes':numbytes} 
        if pathroot is not None:
            session['pages'][pathroot] +=1

#        print '1st session:',session
        userdata[msisdn]={'time':time,'sessioncount':1,'session':[session], 'total_duration':0}

    else: 
        d=userdata[msisdn]
        delta=(time-d['time']).total_seconds()
        if delta < 0: # Kludge: delta may be negative because the input logs is the concatenation of multiple daily logs...
            delta = session_length*2 # ...in that case, we must ensure that a new session is created.
        d['time']=time

#        print 'add_user:',msisdn,time,delta,'secs',pathroot

        if delta > session_length: # we need to create a new session
            newsession={'time':time,'pv':1,'duration':10,'path':pathroot, 'ip':ip, 'ua':useragent, 'pages':Counter(), 'bytes':numbytes}
            if pathroot is not None:
                newsession['pages'][pathroot] +=1
            d['session'].append(newsession)
            d['sessioncount']=d['sessioncount']+1
            if ONEUSER: # in ONEUSER mode, the tool is more verbose and tracks all user moves
                print 'new session:',newsession
        else: # we continue the current session
            d['total_duration'] += delta
            session=d['session'][-1] # get the last session
            session['duration'] = int((time-session['time']).total_seconds())
            if pathroot is not None:
                session['pv'] +=1
                session['pages'][pathroot] +=1
            session['bytes'] += numbytes

            if ONEUSER:
                print session


# Input parameters for PV

##
## Here we go!
##
total =0 # counts the total number of pages with 200 or 302

for line in fileinput.input(files):
    try:
        time,msisdn,useragent,path,retcode,numbytes,ip = parse_log(line)

        if keep(time,msisdn,useragent,path,retcode):
            if retcode == 200 or retcode==302: # the logs comprise a mix of hits (like 303 redirects); we keep only the 200
                total += 1

            pathroot=inc_pageviews(path)
            
            if pathroot is not None:
                hour=time.hour
                hoursum[hour] += 1
                
            add_user(msisdn,time,pathroot, useragent, ip, numbytes)
                
            users[0] += 1 # user[0] counts all pageviews regardless if the patg is right

    except:
        print 'ERROR:',line
        traceback.print_exc()
	raise

# Output
print_users(output) 


